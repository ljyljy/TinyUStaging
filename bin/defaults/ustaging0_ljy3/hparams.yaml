# This files stores hyperparameters for the building and fitting of a model
# in the models library.
#
# Components prefixed __CB are for keras callback hyperparamer settings

__CB_tb: &TB
  # tensorboard
  nickname: "tb"
  class_name: "TensorBoard"
  kwargs: {log_dir: './tensorboard'}

__CB_es: &ES
  # Early stopping
  nickname: "es"
  class_name: "EarlyStopping"
  kwargs: {monitor: 'val_dice', min_delta: 0,
           patience: 80, verbose: 1 , mode: 'max'}

__CB_mcp_clean: &MCP_CLEAN
  # Model checkpoint
  nickname: "mcp_clean"
  class_name: "ModelCheckPointClean"
  kwargs: {filepath: "./model/@epoch_{epoch:02d}_val_dice_{val_dice:.5f}.h5",
           monitor: "val_dice", save_best_only: true, save_weights_only: true,
           verbose: 1, mode: "max"}

__CB_timer: &TIMER
  # Train timer callback
  nickname: "timer"
  class_name: "TrainTimer"
  pass_logger: True
  kwargs: {verbose: True}

__CB_csv: &CSV
  # keras.CSVLogger
  nickname: "csv"
  class_name: "CSVLogger"
  kwargs: {filename: "logs/training.csv", separator: ",", append: true}

datasets:
  # Add dataset IDs --> relative paths here

  #### For testing purposes, we consider just a few datasets here
  dcsm: dataset_configurations/dcsm.yaml
  sedf_sc: dataset_configurations/sedf_sc.yaml
  sedf_st: dataset_configurations/sedf_st.yaml


build:
  #
  # Hyperparameters passed to the Model.build and __init__ methods
  #
  model_class_name: "UStaging_0"
  activation: elu
  depth: 4
  pools: [10, 8, 6, 4]
  kernel_size: 5
  dilation: 2
  transition_window: 1
  complexity_factor: 2
  n_classes: 5

augmenters:
  #
  # On-the-fly augmentation?
  # Leave empty or delete entirely if not
  #
  [
  {cls_name: "GlobalGaussianNoise",
   kwargs: {sigma: 0.1, apply_prob: 0.2}},
  {cls_name: "RegionalGaussianNoise",
   kwargs: {sigma: 0.2,
            min_region_fraction: 0.001,
            max_region_fraction: 0.50,
            log_sample: True,
            apply_prob: 0.2}},
  {cls_name: "GlobalElasticDeformations",
   kwargs: {alpha: [0, 35],
            sigma: [3, 30],
            apply_prob: 0.2}},
  {cls_name: "RegionalErase",
   kwargs: {min_region_fraction: 0.001,
            max_region_fraction: 0.3,
            log_sample: True,
            apply_prob: 0.2}}
  ]

fit:
  #
  # Hyperparameters passed to the Trainer object
  #
  balanced_sampling: True
  use_multiprocessing: False
  channel_mixture: False
  margin: 11

  # Loss function
  loss: ["SparseCategoricalCrossentropy"]
  metrics: ["sparse_categorical_accuracy"]

  # Optimization
  batch_size: 12
  n_epochs: 2000
  verbose: true
  optimizer: "Adam"
  optimizer_kwargs: {lr: 5.0e-06, decay: 0.0, beta_1: 0.9, beta_2: 0.999, epsilon: 1.0e-8}

  # Callbacks
  callbacks: [*TB, *MCP_CLEAN, *TIMER, *CSV, *ES]

__VERSION__: Null
__BRANCH__: Null
__COMMIT__: Null
