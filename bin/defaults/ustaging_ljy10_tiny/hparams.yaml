# This files stores hyperparameters for the building and fitting of a model
# in the models library.
#
# Components prefixed __CB are for keras callback hyperparamer settings

__CB_tb: &TB
  # tensorboard
  nickname: "tb"
  class_name: "TensorBoard"
  kwargs: {log_dir: './tensorboard'}


__CB_es: &ES
  # Early stopping
  nickname: "es"
  class_name: "EarlyStopping"
  kwargs: {monitor: 'val_dice', min_delta: 0,
           patience: 200, verbose: 1 , mode: 'max'}

__CB_mcp_clean: &MCP_CLEAN
  # Model checkpoint
  nickname: "mcp_clean"
  class_name: "ModelCheckPointClean"
  kwargs: {filepath: "./model/@epoch_{epoch:02d}_val_dice_{val_dice:.5f}.h5",
           monitor: "val_dice", save_best_only: true, save_weights_only: true,
           verbose: 1, mode: "max"}
#
#__CB_es: &ES
#  # Early stopping
#  nickname: "es"
#  class_name: "EarlyStopping"
#  kwargs: {monitor: 'val_loss', min_delta: 0,
#           patience: 200, verbose: 1 , mode: 'min'}

#
## TODO: https://www.jianshu.com/p/0711f9e54dd2
##       keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, verbose=0, mode='auto', epsilon=0.0001, cooldown=0, min_lr=0)
#
#
#__CB_mcp_clean: &MCP_CLEAN
#  # Model checkpoint
#  nickname: "mcp_clean"
#  class_name: "ModelCheckPointClean"
#  kwargs: {filepath: "./model/@epoch_{epoch:02d}_val_loss_{val_dice:.5f}.h5",
#           monitor: "val_loss", save_best_only: true, save_weights_only: true,
#           verbose: 1, mode: "min"}

__CB_timer: &TIMER
  # Train timer callback
  nickname: "timer"
  class_name: "TrainTimer"
  pass_logger: True
  kwargs: {verbose: True}

__CB_csv: &CSV
  # keras.CSVLogger
  nickname: "csv"
  class_name: "CSVLogger"
  kwargs: {filename: "logs/training.csv", separator: ",", append: true}

datasets:
  sedf_st: dataset_configurations/sedf_st.yaml
  sedf_sc: dataset_configurations/sedf_sc.yaml
  dcsm: dataset_configurations/dcsm.yaml
#  phys: dataset_configurations/phys.yaml
#  shhs: dataset_configurations/shhs.yaml
  #### Testing datasets
  #dod_o: dataset_configurations/dod_o.yaml
  #dod_h: dataset_configurations/dod_h.yaml


build:
  #
  # Hyperparameters passed to the Model.build and __init__ methods
  #
  model_class_name: "UStaging"
  attention_module_bottom: "SE" # 'SE'  # 推荐在bottom处加注意力（相对减少训练参数 - CBAM:2419898, SE:2412218）
  attention_module_dense: "CBAM" # "SE"  # CBAM：2379231
  ratio_se: 8
  ratio_cbam: 4

  activation: elu
  depth: 4
  pools: [10, 8, 6, 4]
  kernel_size: 5
  dilation: 2   # [1, 2, 3, 2]
  transition_window: 1
  complexity_factor: 2
  n_classes: 5
  batch_shape: [16, 31, 3840, 2]


augmenters:
  #
  # On-the-fly augmentation?
  # Leave empty or delete entirely if not
  #
  [
  {cls_name: "GlobalGaussianNoise",
   kwargs: {sigma: 0.1, apply_prob: 0.2}},
  {cls_name: "RegionalGaussianNoise",
   kwargs: {sigma: 0.2,
            min_region_fraction: 0.001,
            max_region_fraction: 0.50,
            log_sample: True,
            apply_prob: 0.2}},
  {cls_name: "GlobalElasticDeformations",
   kwargs: {alpha: [0, 35],
            sigma: [3, 30],
            apply_prob: 0.2}},
  {cls_name: "RegionalErase",
   kwargs: {min_region_fraction: 0.001,
            max_region_fraction: 0.3,
            log_sample: True,
            apply_prob: 0.2}},
   {cls_name: "ChannelDropout",
    kwargs: {drop_fraction: 0.1,
             apply_prob: 0.1}}
  ]

fit:
  #
  # Hyperparameters passed to the Trainer object
  #
  balanced_sampling: True
  use_multiprocessing: False
  channel_mixture: False
  margin: 15

  # Loss function ->
  loss: ["SparseFocalDiceLoss_ljy"]  # SparseCategoricalCrossentropy/'SparseDiceLoss'/'SparseGeneralizedDiceLoss', 'SparseJaccardDistanceLoss'(smooth=1),
  metrics: ["sparse_categorical_accuracy"]

  # Pass parameters to the loss function here, e.g. class weights
  # Note: class weights only supported by some loss functions!
  # Leave empty or remove field if loss takes no parameters
  loss_kwargs: {
       class_weights: [0.2, 0.2, 0.3, 0.2, 0.2]  # 'SparseFocalLoss'
  }

  # Ignore class in loss computation (e.g. to ignore 'UNKNOWN'/'MOVEMENT' other rare classes)
  # Comment out or set to Null to not ignore any classes
  ignore_class_int: 5

  # Optimization
  batch_size: 16
  n_epochs: 2000
  verbose: true
  optimizer: "Adam"
  optimizer_kwargs: {lr: 5.0e-06, decay: 0.0, beta_1: 0.9, beta_2: 0.999, epsilon: 1.0e-8}
#  optimizer_kwargs: {lr: 1.0e-07, amsgrad: True, decay: 0.0, beta_1: 0.9, beta_2: 0.999, epsilon: 1.0e-8}

  # Callbacks
  callbacks: [*TB, *MCP_CLEAN, *TIMER, *CSV, *ES]

__VERSION__: Null
__BRANCH__: Null
__COMMIT__: Null
